{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dq07xg_YEW0C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4f02538-1e5e-4609-9e94-b1b129d9bee0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter input: {\"token\":\"35382\",\"symbol\":\"NIFTY31OCT24FUT\",\"name\":\"NIFTY\",\"expiry\":\"31OCT2024\",\"strike\":\"-1.000000\",\"lotsize\":\"25\",\"instrumenttype\":\"FUTIDX\",\"exch_seg\":\"NFO\",\"tick_size\":\"5.000000\"}\n",
            "Results found:\n",
            "Kotak: {'OptionType': '', 'exchange': 'NSE', 'token': '35382', 'expiry': '31OCT24', 'name': 'NIFTY', 'instrumentToken': '12152', 'instrumentType': 'FI', 'ISIN': '', 'lastPrice': '25990.15', 'lotSize': '25', 'multiplier': '1', 'CompanyName': '', 'nudge': '', 'optionType': 'XX', 'segment': 'FO', 'strike': '0.0', 'tickSize': '0.05'}\n",
            "Fyers: {'ISIN': '', 'optionType': 'XX', 'expiryDate': '25-10-2024', 'instrumentToken': '1.01E+14', 'extraField2': '', 'extraField3': '0', 'extraField4': '0', 'strike': '-1', 'instrumentName': 'NIFTY 24 Oct 31 FUT', 'lotSize': '25', 'tickSize': '10', 'marketHours': '0915-1530|1815-1915:', 'multiplier': '11', 'noneField': '1.01E+14', 'token': '35382', 'name': 'NIFTY', 'series': '11', 'lastPrice': '0.05', 'timeToExpire': '26000', 'tradingSymbol': 'NIFTY24OCTFUT'}\n",
            "Icici: {'52WeeksHigh': '', '52WeeksLow': '', 'AGM': '', 'AON': '', 'AVMBuyMargin': '', 'AVMSellMargin': '', 'AssetInstrument': '', 'AssetName': '', 'AssetToken': '0', 'AuctionMarketEligibility': '', 'AuctionMarketStatus': '0', 'AuctionlMarketEligibility': '', 'BCastFlag': '', 'BasePrice': '2478880', 'BoardLotQty': '', 'Bonus': '', 'BookClsEndDate': '', 'BookClsStartDate': '', 'CALevel': '0', 'CompanyName': 'NIFTY 50', 'CreditRating': '', 'DateOfDeListing': '', 'DateOfListing': '', 'DeleteFlag': '', 'Dividends': '', 'EGM': '', 'ExAllowed': 'NFO', 'ExRejectionAllowed': '', 'ExcerciseEndDate': '', 'ExcerciseStartDate': '', 'ExcerciseStyle': '', 'name': 'NIFTY 50', 'ExpiryDate': '31-Oct-24', 'ExpulsionDate': '', 'ExtrinsicValue': '0', 'FaceValue': '', 'FreezePercent': '', 'FreezeQty': '0', 'GroupName': '', 'HighDate': '', 'HighPriceRange': '27267.7', 'ISIN': '', 'InstrumentName': 'FUTIDX', 'InstrumentType': '', 'Interest': '', 'InterestPaymentDate': '', 'IntrinsicValue': '0', 'IsCorpAdjusted': '', 'IsThisAsset': '', 'IssueCapital': '0', 'IssueMaturityDate': '', 'IssuePrice': '', 'IssueRate': '0', 'IssueStartDate': '', 'LifeTimeHigh': '', 'LifeTimeLow': '', 'ListingDate': '', 'LocalUpdateDateTime': '', 'LocalUpdateDatetime': '', 'LotSize': '25', 'Lotsize': '', 'LowDate': '', 'LowPriceRange': '22309.95', 'MF': '1-Mon', 'MFill': '', 'MarginPercentage': '12901075', 'MarketLot': '', 'MinimumLotQty': '0', 'NDEDate': '', 'NDSDate': '', 'Name': '', 'NdFlag': '', 'NoDeliveryEndDate': '', 'NoDeliveryStartDate': '', 'NormalMarketEligibility': '', 'NormalMarketStatus': '0', 'OddLotMarketEligibility': '', 'OddLotMarketStatus': '0', 'OddLotlMarketEligibility': '', 'OldToken': '0', 'OptionType': 'XX', 'ParticipantInMarketIndex': '', 'PermittedToTrade': '0', 'PlAllowed': '', 'ReAdmissionDate': '', 'RecordDate': '', 'Remarks': '', 'Rights': '', 'ScripCode': '', 'ScripID': '', 'ScripName': '', 'SecurityExpiryDate': '', 'Series': 'FUTURE', 'ShortName': 'NIFTY', 'SpotMarketEligibility': '', 'SpotMarketStatus': '0', 'StrikePrice': '0', 'SuspStatus': '', 'SuspensionReason': '', 'Suspensiondate': '', 'Symbol': '', 'TickSize': '5', 'token': '35382', 'WarningPercent': '', 'WarningQty': '0', 'avmflag': '', 'ticksize': ''}\n",
            "Angel: {'token': '35382', 'instrumentName': 'NIFTY31OCT24FUT', 'name': 'NIFTY', 'expiry': '31OCT2024', 'strike': '-1', 'lotsize': '25', 'instrumenttype': 'FUTIDX', 'exchange': 'NFO', 'tick_size': '5'}\n",
            "Zerodha: {'instrument_token': '9057794', 'token': '35382', 'instrumentName': 'NIFTY24OCTFUT', 'name': 'NIFTY', 'last_price': '0', 'expiry': '2024-10-31', 'strike': '0.0', 'tick_size': '0.05', 'lot_size': '25', 'instrument_type': 'FUT', 'segment': 'NFO-FUT', 'exchange': 'NFO'}\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import json\n",
        "\n",
        "# Sample broker data structure (paths to CSV files)\n",
        "broker_data = {\n",
        "    \"kotak\": \"kotak.csv\",\n",
        "    \"fyers\": \"fyers.csv\",\n",
        "    \"icici\": \"icici.csv\",\n",
        "    \"angel\": \"angel.csv\",\n",
        "    \"zerodha\": \"zerodha.csv\"\n",
        "}\n",
        "\n",
        "# Function to check ISIN or symbol in a single broker's data\n",
        "def check_broker_for_isin_or_symbol(broker_name, filepath, input_isin=None, input_symbol=None, input_token=None, input_exchange=None):\n",
        "    matches = []\n",
        "\n",
        "    with open(filepath, 'r') as file:\n",
        "        reader = csv.DictReader(file)\n",
        "        for row in reader:\n",
        "            # Check for ISIN match if provided\n",
        "            if input_isin and row.get(\"ISIN\") and row.get(\"ISIN\").strip().lower() == input_isin.lower():\n",
        "                matches.append(row)\n",
        "\n",
        "            # Check for token match if no ISIN match or in addition\n",
        "            elif input_token and row.get(\"token\") and row.get(\"token\").strip().lower() == input_token.strip().lower():\n",
        "                matches.append(row)\n",
        "\n",
        "    # Filter matches by exchange if there are multiple results and an exchange input is provided\n",
        "    #if len(matches) > 1 and input_exchange:\n",
        "        #matches = [row for row in matches if row.get(\"exchange\") and row.get(\"exchange\").strip().lower() == input_exchange.lower()]\n",
        "\n",
        "\n",
        "  #if multiple matches found,filter by symbol/name\n",
        "    if len(matches) > 1 and input_symbol:\n",
        "        matches = [row for row in matches if row.get(\"name\") and row.get(\"name\").strip().lower().replace(\" \",\"\") == input_symbol.strip().lower().replace(\" \",\"\")]\n",
        "    # Return the first match or None if no match found\n",
        "    return matches[0] if matches else None\n",
        "\n",
        "# Function to query brokers for ISIN or symbol\n",
        "def query_brokers(input_isin=None, input_symbol=None, input_token=None, input_exchange=None):\n",
        "    results = {}\n",
        "\n",
        "    # Iterate through each broker's data and check for the ISIN or symbol\n",
        "    for broker, filepath in broker_data.items():\n",
        "        result = check_broker_for_isin_or_symbol(broker, filepath, input_isin, input_symbol, input_token, input_exchange)\n",
        "        if result:\n",
        "            results[broker] = result\n",
        "\n",
        "    return results\n",
        "\n",
        "# Function to handle user input and broker-specific extraction\n",
        "def query_script_mapping(json_data):\n",
        "    # Extract ISIN, symbol, token, and exchange from JSON data\n",
        "    input_isin = json_data.get(\"ISIN\")\n",
        "    input_symbol = json_data.get(\"name\")\n",
        "    input_token = json_data.get(\"token\")\n",
        "    input_exchange = json_data.get(\"exchange\")\n",
        "\n",
        "    # Query brokers for the ISIN, symbol, or token\n",
        "    results = query_brokers(input_isin, input_symbol, input_token, input_exchange)\n",
        "\n",
        "    if results:\n",
        "        print(\"Results found:\")\n",
        "        for broker, details in results.items():\n",
        "            print(f\"{broker.capitalize()}: {details}\")\n",
        "    else:\n",
        "        print(\"No mapping found.\")\n",
        "\n",
        "def main():\n",
        "    # Prompt user to input JSON data\n",
        "    user_input = input(\"Please enter input: \")\n",
        "\n",
        "    try:\n",
        "        # Parse the JSON data from user input\n",
        "        json_data = json.loads(user_input)\n",
        "\n",
        "        query_script_mapping(json_data)\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"Invalid JSON format. Please try again.\")\n",
        "\n",
        "# Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get random row data as json\n",
        "\n",
        "import pandas as pd\n",
        "import random\n",
        "import json\n",
        "\n",
        "def get_random_row_as_json(csv_file_path):\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(csv_file_path)\n",
        "\n",
        "    # Select a random row\n",
        "    random_row = df.sample(n=1)\n",
        "\n",
        "    # Convert the row to a dictionary and stringify all keys and values\n",
        "    row_dict = random_row.to_dict(orient='records')[0]\n",
        "    row_str_dict = {str(key): str(value) for key, value in row_dict.items()}\n",
        "\n",
        "    # Convert to JSON format\n",
        "    row_json = json.dumps(row_str_dict)\n",
        "    return row_json\n",
        "\n",
        "# Example usage\n",
        "csv_file_path = 'kotak.csv'  # Replace with your CSV file path\n",
        "random_row_json = get_random_row_as_json(csv_file_path)\n",
        "print(random_row_json)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otu610uui6qW",
        "outputId": "a90822cb-246e-4cfb-80a3-6b59f10c1ddd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"ISIN\": \"nan\", \"extrafield\": \"nan\", \"exchange\": \"NSE\", \"expiry\": \"12-Apr-22\", \"name\": \"FINNIFTY\", \"instrumentToken\": \"27774\", \"instrumentType\": \"OI\", \"lastPrice\": \"33.3\", \"lotSize\": \"40\", \"multiplier\": \"1\", \"Companyname\": \"nan\", \"optionType\": \"PE\", \"segment\": \"FO\", \"strike\": \"14200.0\", \"tickSize\": \"0.05\", \"token\": \"45642\"}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-42-e1a99c85908d>:7: DtypeWarning: Columns (0,1,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(csv_file_path)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get headers from a csv file\n",
        "\n",
        "import csv\n",
        "\n",
        "# List of CSV file names\n",
        "csv_files = ['kotak.csv']  # Replace with your actual file names\n",
        "\n",
        "# Dictionary to store headers from each file\n",
        "headers_dict = {}\n",
        "\n",
        "# Loop through each CSV file to extract headers\n",
        "for csv_file in csv_files:\n",
        "    try:\n",
        "        with open(csv_file, mode='r') as file:\n",
        "            reader = csv.reader(file)\n",
        "            headers = next(reader)  # Extract the first row as headers\n",
        "            headers_dict[csv_file] = headers  # Store headers in the dictionary\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File '{csv_file}' not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while processing '{csv_file}': {e}\")\n",
        "\n",
        "# Print the headers for each file\n",
        "for file, headers in headers_dict.items():\n",
        "    print(f\"Headers from '{file}': {headers}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEJG81A9M50T",
        "outputId": "679f96b7-48e5-49ad-f128-c76023b109e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Headers from 'kotak.csv': ['ISIN', 'extrafield', 'exchange', 'expiry', 'name', 'instrumentToken', 'instrumentType', 'lastPrice', 'lotSize', 'multiplier', 'Companyname', 'optionType', 'segment', 'strike', 'tickSize', 'token']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#change column header in csv file\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Read the CSV file into a DataFrame\n",
        "file_path = 'kotak1.csv'  # Path to your CSV file\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Step 2: Display the original headers\n",
        "print(\"Original Headers:\")\n",
        "print(df.columns.tolist())\n",
        "\n",
        "# Step 3: Strip whitespace from header names\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# Step 4: Check if 'ISINCode' exists and rename it to 'ISIN'\n",
        "if 'instrumentName' in df.columns:\n",
        "    df.rename(columns={'instrumentName': 'name'}, inplace=True)\n",
        "    print(\"Header 'ISINCode' has been replaced with 'ISIN'.\")\n",
        "else:\n",
        "    print(\"Header 'ISINCode' not found. No changes made.\")\n",
        "\n",
        "# Step 5: Display the modified headers\n",
        "print(\"Modified Headers:\")\n",
        "print(df.columns.tolist())\n",
        "\n",
        "# Step 6: Save the modified DataFrame back to a CSV file\n",
        "df.to_csv('kotak1.csv', index=False)  # Save with a new name to avoid overwriting\n",
        "\n",
        "print(\"Modified DataFrame saved as 'icici_modified.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFLBaJLAWVLQ",
        "outputId": "af04514c-0ff1-4c65-993b-fff7b268196b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-c8b1240052b1>:5: DtypeWarning: Columns (0,7,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Headers:\n",
            "['OptionType', 'exchange', 'token', 'expiry', 'instrumentName', 'instrumentToken', 'instrumentType', 'ISIN', 'lastPrice', 'lotSize', 'multiplier', 'CompanyName', 'nudge', 'optionType', 'segment', 'strike', 'tickSize']\n",
            "Header 'ISINCode' has been replaced with 'ISIN'.\n",
            "Modified Headers:\n",
            "['OptionType', 'exchange', 'token', 'expiry', 'name', 'instrumentToken', 'instrumentType', 'ISIN', 'lastPrice', 'lotSize', 'multiplier', 'CompanyName', 'nudge', 'optionType', 'segment', 'strike', 'tickSize']\n",
            "Modified DataFrame saved as 'icici_modified.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert txt to csv (txt separated by '|')\n",
        "\n",
        "import csv\n",
        "\n",
        "# Define input and output file paths\n",
        "input_file = 'input.txt'  # Replace with your actual input txt file path\n",
        "output_file = 'output.csv'\n",
        "\n",
        "# Read from the input text file\n",
        "with open(input_file, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Open the output CSV file in write mode\n",
        "with open(output_file, 'w', newline='') as csvfile:\n",
        "    csv_writer = csv.writer(csvfile)\n",
        "\n",
        "    # Write header from the first line\n",
        "    header = lines[0].strip().split('|')\n",
        "    csv_writer.writerow(header)\n",
        "\n",
        "    # Write each row of data\n",
        "    for line in lines[1:]:\n",
        "        row = line.strip().split('|')\n",
        "        csv_writer.writerow(row)\n",
        "\n",
        "print(f\"Converted text file to {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBX3rLljHmDF",
        "outputId": "249d828c-aca4-4cd2-eede-a2fd34cc5875"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted text file to output.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#add headers to file,fyers.csv as no headers are present\n",
        "\n",
        "import csv\n",
        "\n",
        "# Define the headers based on the data structure\n",
        "headers = [\n",
        "    \"instrumentToken\", \"instrumentName\", \"series\", \"lastPrice\",\n",
        "    \"tickSize\", \"ISI\", \"marketHours\", \"expiryDate\",\n",
        "    \"extraField1\", \"tradingSymbol\", \"lotSize\", \"multiplier\",\n",
        "    \"optionType\", \"orderType\", \"timeToExpire\", \"flag\",\n",
        "    \"duplicateToken\", \"noneField\", \"extraField2\", \"extraField3\", \"extraField4\"\n",
        "]\n",
        "\n",
        "# Function to add headers to the CSV file and clean tradingSymbol column\n",
        "def add_headers_to_csv(input_file, output_file):\n",
        "    with open(input_file, 'r') as infile, open(output_file, 'w', newline='') as outfile:\n",
        "        # Create a CSV writer object\n",
        "        writer = csv.writer(outfile)\n",
        "\n",
        "        # Write the headers\n",
        "        writer.writerow(headers)\n",
        "\n",
        "        # Write the original data\n",
        "        for row in infile:\n",
        "            # Split the row into columns\n",
        "            data = row.strip().split(',')\n",
        "\n",
        "            # Check if the number of columns matches the headers\n",
        "            if len(data) == len(headers):\n",
        "                # Clean the tradingSymbol field by removing \"NSE:\" prefix if present\n",
        "                if \"NSE:\" in data[9]:  # tradingSymbol is at index 9\n",
        "                    data[9] = data[9].replace(\"NSE:\", \"\")  # Remove the prefix\n",
        "\n",
        "                writer.writerow(data)\n",
        "            else:\n",
        "                # Print a warning if the row size is not as expected\n",
        "                print(f\"Warning: Row skipped due to size mismatch: {data}\")\n",
        "\n",
        "# Define the input and output file paths\n",
        "input_csv_file = 'NSE_FO.csv'  # Replace with your original CSV file path\n",
        "output_csv_file = 'fyers4.csv'  # Replace with your desired output file path\n",
        "\n",
        "# Call the function to add headers and clean the tradingSymbol column\n",
        "add_headers_to_csv(input_csv_file, output_csv_file)\n",
        "\n",
        "print(f\"Headers added successfully and tradingSymbol cleaned. Output file: {output_csv_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sE7fKXL9PKjn",
        "outputId": "0dcdee59-07b1-465b-cc5f-dc45fcedef69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Headers added successfully and tradingSymbol cleaned. Output file: fyers4.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert txt to csv (txt separated by \"\")\n",
        "\n",
        "import csv\n",
        "\n",
        "# Specify the input text file and output CSV file\n",
        "input_file = 'icici4.txt'  # Replace with your actual text file name\n",
        "output_file = '/content/data4.csv'\n",
        "\n",
        "# Read the data from the text file\n",
        "with open(input_file, 'r') as file:\n",
        "    # Read all lines from the file\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Remove quotes and strip whitespace from each line\n",
        "cleaned_lines = [line.replace('\"', '').strip() for line in lines]\n",
        "\n",
        "# Write to CSV\n",
        "with open(output_file, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    for line in cleaned_lines:\n",
        "        writer.writerow(line.split(','))\n",
        "\n",
        "print(f\"CSV file '{output_file}' created successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIk4fEK9Ibrs",
        "outputId": "5a5e629b-14ae-4425-c654-dd6314005ec9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file '/content/data4.csv' created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#merge 2 csv\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def merge_csv_files(file1, file2, output_file):\n",
        "    # Read the CSV files\n",
        "    df1 = pd.read_csv(file1)\n",
        "    df2 = pd.read_csv(file2,low_memory=False)\n",
        "\n",
        "    # Strip whitespace from column headers to standardize\n",
        "    df1.columns = df1.columns.str.strip()\n",
        "    df2.columns = df2.columns.str.strip()\n",
        "\n",
        "    # Get the union of columns from both DataFrames\n",
        "    all_columns = sorted(list(set(df1.columns).union(set(df2.columns))))\n",
        "\n",
        "    # Reindex both DataFrames with the union of columns, filling missing values with blanks\n",
        "    df1 = df1.reindex(columns=all_columns, fill_value=\"\")\n",
        "    df2 = df2.reindex(columns=all_columns, fill_value=\"\")\n",
        "\n",
        "    # Concatenate the two DataFrames\n",
        "    merged_df = pd.concat([df1, df2], ignore_index=True)\n",
        "\n",
        "    # Write the merged DataFrame to the output file\n",
        "    merged_df.to_csv(output_file, index=False)\n",
        "\n",
        "# Example usage\n",
        "merge_csv_files(\"output.csv\", \"output1.csv\", \"kotak1.csv\")\n"
      ],
      "metadata": {
        "id": "OPjGxju9bNHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert txt to csv\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Define the file paths\n",
        "input_file = 'KTK.txt'  # Replace with the actual path of your text file\n",
        "output_file = 'output1.csv'  # Replace with the desired output CSV file name\n",
        "\n",
        "# Step 2: Read the text file as a DataFrame with pipe ('|') separator\n",
        "df = pd.read_csv(input_file, sep='|' ,encoding='ISO-8859-1')\n",
        "\n",
        "# Step 3: Save the DataFrame as a CSV file\n",
        "df.to_csv(output_file, index=False)  # Set index=False to avoid saving the index\n",
        "\n",
        "print(f\"Text file '{input_file}' has been successfully converted to CSV as '{output_file}'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBPx5i6tad4y",
        "outputId": "e46348cf-3c9d-41e0-8355-992200432a44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text file 'KTK.txt' has been successfully converted to CSV as 'output1.csv'.\n"
          ]
        }
      ]
    }
  ]
}